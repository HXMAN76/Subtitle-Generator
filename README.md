# üé¨ Subtitle Generator & Translator

A production-ready, offline subtitle generation and translation system with **REST API backend**. Uses **faster-whisper** for high-speed transcription and **custom-trained XLarge Transformer NMT models** for neural machine translation to **11 Indic languages** with **per-language tokenizers** and **lazy model loading**.

**API Version**: 2.1.0 | **NMT Models**: XLarge (~385M params) | **Languages**: as, bn, gu, hi, kn, ml, mr, or, pa, ta, te

> ‚ö†Ô∏è **Training Status**: XLarge models are currently being trained. Results pending.

## ‚ú® Features

| Feature | Description |
|---------|-------------|
| üéôÔ∏è **Speech-to-Text** | High-speed transcription using faster-whisper (3-4x faster than OpenAI Whisper) |
| üåê **XLarge NMT** | Custom-trained 385M parameter Transformer for state-of-the-art translation |
| üáÆüá≥ **11 Indic Languages** | Hindi, Tamil, Telugu, Bengali, Marathi, Gujarati, Kannada, Malayalam, Punjabi, Odia, Assamese |
| üî§ **Per-Language Tokenizers** | Optimized tokenizer for each language (48K vocab for Dravidian) |
| üåê **REST API** | FastAPI backend with Swagger docs, background jobs, file uploads |
| üìù **Subtitle Generation** | SRT and VTT format output |
| üîå **Offline Operation** | Runs completely locally - no cloud APIs needed |
| ‚ö° **H100 Optimized** | Training optimized for H100/A100, inference on RTX 6000 Ada |

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         SUBTITLE GENERATOR v2.0                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ                      FastAPI Backend (api.py)                       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                                     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   GET  /languages ‚îÄ‚îÄ‚ñ∫ Available target languages                    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   POST /upload?target_lang=hi ‚îÄ‚îÄ‚ñ∫ Background Job                    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   POST /translate?target_lang=as ‚îÄ‚îÄ‚ñ∫ Instant Response               ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   GET  /download/{id}/translated ‚îÄ‚îÄ‚ñ∫ SRT/VTT file                   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                     ‚îÇ                                       ‚îÇ
‚îÇ                                     ‚ñº                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ                     Processing Pipeline                             ‚îÇ    ‚îÇ 
‚îÇ  ‚îÇ                                                                     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Video  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Audio Extract‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Transcribe  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇSubtitles‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Input  ‚îÇ    ‚îÇ   (FFmpeg)   ‚îÇ    ‚îÇ(faster-whisper)‚îÇ ‚îÇ  (SRT)  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                            ‚îÇ                        ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                            ‚ñº                        ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ    Multi-Language Translator (Lazy Loading)    ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ                                                ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ  ‚îÇ as  ‚îÇ ‚îÇ bn  ‚îÇ ‚îÇ gu  ‚îÇ ‚îÇ hi  ‚îÇ ‚îÇ ... ‚îÇ       ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ       (models loaded on-demand)                 ‚îÇ    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Project Structure

```
Subtitle-Generator/
‚îú‚îÄ‚îÄ api.py                      # FastAPI REST backend
‚îú‚îÄ‚îÄ app.py                      # CLI application (3-step pipeline)
‚îú‚îÄ‚îÄ config.py                   # Configuration settings
‚îú‚îÄ‚îÄ requirements.txt            # Dependencies
‚îÇ
‚îú‚îÄ‚îÄ src/                        # Core modules
‚îÇ   ‚îú‚îÄ‚îÄ audio_processor.py      # Video ‚Üí Audio extraction
‚îÇ   ‚îú‚îÄ‚îÄ transcriber.py          # faster-whisper transcription
‚îÇ   ‚îú‚îÄ‚îÄ translator.py           # Multi-language NMT wrapper (lazy loading)
‚îÇ   ‚îú‚îÄ‚îÄ subtitle_generator.py   # SRT/VTT generation
‚îÇ   ‚îî‚îÄ‚îÄ nmt/                    # Neural Machine Translation
‚îÇ       ‚îú‚îÄ‚îÄ model/              # Transformer architecture
‚îÇ       ‚îú‚îÄ‚îÄ training/           # Training pipeline
‚îÇ       ‚îú‚îÄ‚îÄ inference/          # Translation inference
‚îÇ       ‚îú‚îÄ‚îÄ config.py           # Model configs (base/large/xlarge)
‚îÇ       ‚îî‚îÄ‚îÄ languages.py        # Language definitions
‚îÇ
‚îú‚îÄ‚îÄ scripts/                    # CLI tools
‚îÇ   ‚îú‚îÄ‚îÄ train_tokenizer.py     # Train per-language tokenizers
‚îÇ   ‚îú‚îÄ‚îÄ train_nmt.py           # Train translation model
‚îÇ   ‚îú‚îÄ‚îÄ train_pipeline.sh      # Full training pipeline
‚îÇ   ‚îî‚îÄ‚îÄ evaluate_nmt.py        # Evaluate model BLEU scores
‚îÇ
‚îú‚îÄ‚îÄ models/translation/         # Trained models (lazy loaded)
‚îÇ   ‚îú‚îÄ‚îÄ hi/                     # Hindi model
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.model     # Per-language tokenizer (32K vocab)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ best.pt             # XLarge model (~385M params)
‚îÇ   ‚îú‚îÄ‚îÄ ta/                     # Tamil model  
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.model     # Per-language tokenizer (48K vocab, Dravidian)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ best.pt
‚îÇ   ‚îî‚îÄ‚îÄ .../                    # Other language models
‚îÇ
‚îú‚îÄ‚îÄ tests/                      # Unit tests
‚îú‚îÄ‚îÄ docs/                       # Documentation
‚îú‚îÄ‚îÄ data/                       # Training data
‚îî‚îÄ‚îÄ output/                     # Generated subtitles
```

---

## üöÄ Quick Start

### Prerequisites

- **Python 3.8+**
- **FFmpeg** (for audio processing)
- **CUDA** (optional, for GPU acceleration)

### Installation

```bash
# Clone repository
git clone https://github.com/your-repo/Subtitle-Generator.git
cd Subtitle-Generator

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

---

## üåê REST API Usage

### Start the Server

```bash
# Development (with auto-reload)
uvicorn api:app --reload --host 0.0.0.0 --port 8000

# Production
uvicorn api:app --host 0.0.0.0 --port 8000 --workers 4
```

### Interactive Docs

Open in browser: **http://localhost:8000/docs**

### API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | API info |
| `GET` | `/health` | Health check & available languages |
| `GET` | `/languages` | **List supported/available languages** |
| `GET` | `/docs` | **Swagger UI** (interactive docs) |
| `POST` | `/upload?target_lang=hi` | Upload video ‚Üí Start processing |
| `GET` | `/jobs/{id}` | Check job status & progress |
| `GET` | `/jobs` | List all jobs |
| `GET` | `/download/{id}/original` | Download original subtitles |
| `GET` | `/download/{id}/translated` | Download translated subtitles |
| `POST` | `/translate` | Translate single text |
| `POST` | `/translate/batch` | Translate multiple texts |
| `DELETE` | `/jobs/{id}` | Delete job & files |

### Example: Upload Video

```bash
# Upload with Hindi subtitles (default)
curl -X POST "http://localhost:8000/upload" \
  -F "file=@your_video.mp4"

# Upload with Assamese subtitles
curl -X POST "http://localhost:8000/upload?translate=true&target_lang=as" \
  -F "file=@your_video.mp4"

# Upload with Bengali subtitles
curl -X POST "http://localhost:8000/upload?translate=true&target_lang=bn" \
  -F "file=@your_video.mp4"

# Response: {"job_id": "abc123", "status_url": "/jobs/abc123"}
```

### Example: Check Job Status

```bash
curl http://localhost:8000/jobs/abc123

# Response: {"status": "completed", "progress": 1.0, ...}
```

### Example: Translate Text

```bash
# Translate to Hindi (default)
curl -X POST "http://localhost:8000/translate" \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello world"}'

# Translate to Tamil
curl -X POST "http://localhost:8000/translate" \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello world", "target_lang": "ta"}'

# Check available languages
curl http://localhost:8000/languages
```

---

## üíª CLI Usage

### Process a Video

```bash
# Edit video_path in app.py first
python app.py
```

### Interactive Translation

```bash
python scripts/translate.py --checkpoint models/translation/best.pt --interactive
```

---

## ‚öôÔ∏è Configuration

Edit `config.py`:

```python
# Whisper settings
WHISPER_MODEL_SIZE = "tiny"   # tiny, base, small, medium, large-v3
WHISPER_DEVICE = "cuda"       # Auto-detected (cuda/cpu)

# Translation (Multi-language)
# Supported: as, bn, gu, hi, kn, ml, mr, or, pa, ta, te
SOURCE_LANGUAGE = "en"
TARGET_LANGUAGE = "hi"        # Default target language

# Subtitle format
SUBTITLE_FORMAT = "srt"       # srt, vtt
```

### Model Comparison

| Model | Speed | Accuracy | VRAM | Use Case |
|-------|-------|----------|------|----------|
| `tiny` | ‚ö°‚ö°‚ö°‚ö°‚ö° | 70% | 1GB | Testing |
| `base` | ‚ö°‚ö°‚ö°‚ö° | 80% | 1GB | General |
| `small` | ‚ö°‚ö°‚ö° | 88% | 2GB | **Recommended** |
| `medium` | ‚ö°‚ö° | 92% | 5GB | Quality |
| `large-v3` | ‚ö° | 95% | 10GB | Professional |

---

## üß† Translation Model

### Architecture: XLarge Transformer

> ‚ö†Ô∏è **Training Status**: Models are currently being trained. BLEU scores pending.

| Parameter | Value |
|-----------|-------|
| **Type** | Transformer (Encoder-Decoder) |
| **Parameters** | ~385 Million |
| **Encoder Layers** | 12 |
| **Decoder Layers** | 12 |
| **Attention Heads** | 16 |
| **Hidden Dimension** | 1024 |
| **Feed-Forward** | 4096 |
| **Tokenizer** | Per-language SentencePiece |
| **Vocab Size** | 32K (Indo-Aryan) / 48K (Dravidian) |
| **Dataset** | AI4Bharat Samanantar (49.6M pairs) |

### Supported Languages

| Code | Language | Family | Tokenizer Vocab |
|------|----------|--------|----------------|
| `hi` | Hindi | Indo-Aryan | 32K BPE |
| `bn` | Bengali | Indo-Aryan | 32K BPE |
| `mr` | Marathi | Indo-Aryan | 32K BPE |
| `gu` | Gujarati | Indo-Aryan | 32K BPE |
| `pa` | Punjabi | Indo-Aryan | 32K BPE |
| `or` | Odia | Indo-Aryan | 32K BPE |
| `as` | Assamese | Indo-Aryan | 32K BPE |
| `ta` | Tamil | **Dravidian** | **48K Unigram** |
| `te` | Telugu | **Dravidian** | **48K Unigram** |
| `kn` | Kannada | **Dravidian** | **48K Unigram** |
| `ml` | Malayalam | **Dravidian** | **48K Unigram** |

### Train Your Own Model

```bash
# 1. Train using the automated pipeline (Recommended)
# Handles data splitting, tokenizer training, and model training
bash scripts/train_pipeline.sh ta

# OR Manual Steps:

# 1. Train per-language tokenizer (optimized for each language)
python scripts/train_tokenizer.py --target-lang ta

# 2. Train XLarge model (~385M params)
python scripts/train_nmt.py --target-lang ta --config xlarge --streaming

# 3. Evaluate
python scripts/evaluate_nmt.py --language ta
```

---

## üìä Performance

### Time Estimates (2-hour video)

| Step | Time (GPU) | Time (CPU) |
|------|------------|------------|
| Audio Extraction | 30 sec | 30 sec |
| Transcription | 15-25 min | 60-90 min |
| Translation | 5-10 min | 15-20 min |
| **Total** | **25-40 min** | **90-120 min** |

### Optimizations Applied

- ‚úÖ **faster-whisper**: 3-4x faster than OpenAI Whisper
- ‚úÖ **Batch Translation**: Efficient GPU utilization
- ‚úÖ **Background Jobs**: Non-blocking API requests
- ‚úÖ **Lazy Loading**: Models load on-demand (memory efficient)
- ‚úÖ **Per-Language Tokenizers**: Optimized vocabulary per language
- ‚úÖ **XLarge Architecture**: 385M params for maximum quality
- ‚úÖ **Model Caching**: Loaded models stay in memory

---

## üõ†Ô∏è Troubleshooting

| Issue | Solution |
|-------|----------|
| FFmpeg not found | Install FFmpeg and add to PATH |
| CUDA out of memory | Use smaller Whisper model (`tiny` or `base`) |
| Translation returns original | Ensure `models/translation/{lang}/best.pt` exists |
| Slow transcription | Check `WHISPER_DEVICE` is `cuda` |
| API port in use | Change port: `uvicorn api:app --port 8001` |
| Language not available | Check `/languages` endpoint for available models |

---

## üì¶ Dependencies

### Core
- **faster-whisper** - CTranslate2-optimized Whisper
- **torch** - Neural network framework
- **sentencepiece** - Tokenization
- **moviepy** - Video processing

### API
- **fastapi** - REST API framework
- **uvicorn** - ASGI server
- **python-multipart** - File uploads

### System
- **FFmpeg** - Audio extraction
- **CUDA** (optional) - GPU acceleration

---

## üéØ Roadmap

- [x] faster-whisper integration
- [x] Full audio mode
- [x] Custom NMT model
- [x] REST API backend
- [x] Multiple language pairs (11 Indic languages)
- [x] Multi-language lazy loading (v2.0.0)
- [x] Per-language model files
- [ ] Music detection (`[‚ô™ Music ‚ô™]`)
- [ ] Web UI frontend
- [ ] Docker deployment

---

## üìù License

MIT License - free for personal and commercial use.

---

## üôè Acknowledgments

- [faster-whisper](https://github.com/guillaumekln/faster-whisper) - High-speed transcription
- [FastAPI](https://fastapi.tiangolo.com/) - Modern API framework
- [AI4Bharat Samanantar](https://huggingface.co/datasets/ai4bharat/samanantar) - Multi-language training data
- [SentencePiece](https://github.com/google/sentencepiece) - Tokenization
