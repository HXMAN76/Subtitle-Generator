{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baec7b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hxman/Work/Subtitle-Generator/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"cfilt/iitb-english-hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b47e786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': {'en': 'Give your application an accessibility workout', 'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'}}\n"
     ]
    }
   ],
   "source": [
    "# print(ds)\n",
    "print(ds['train'][0])\n",
    "# print(ds['test'][0])\n",
    "# print(ds['validation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b661d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'target': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें', 'source': 'Give your application an accessibility workout'}, {'target': 'एक्सेर्साइसर पहुंचनीयता अन्वेषक', 'source': 'Accerciser Accessibility Explorer'}, {'target': 'निचले पटल के लिए डिफोल्ट प्लग-इन खाका', 'source': 'The default plugin layout for the bottom panel'}, {'target': 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका', 'source': 'The default plugin layout for the top panel'}, {'target': 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है', 'source': 'A list of plugins that are disabled by default'}]\n",
      "[{'target': 'आपकी कार में ब्लैक बॉक्स?', 'source': 'A black box in your car?'}, {'target': 'जबकि अमेरिका के सड़क योजनाकार, ध्वस्त होते हुए हाईवे सिस्टम को सुधारने के लिए धन की कमी से जूझ रहे हैं, वहीं बहुत-से लोग इसका समाधान छोटे से ब्लैक बॉक्स में देख रहे हैं, जो आपकी कार के डैशबोर्ड पर सफ़ाई से फिट हो जाता है।', 'source': \"As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\"}, {'target': 'यह डिवाइस, जो मोटर-चालक द्वारा वाहन चलाए गए प्रत्येक मील को ट्रैक करती है तथा उस सूचना को अधिकारियों को संचारित करती है, आजकल अमेरिका की प्रमुख सड़कों का वित्त-पोषण करने के लिए पुराने हो चुके सिस्टम का जीर्णोद्धार करने के लिए वाशिंगटन और राज्य नियोजन कार्यालय के लिए एक विवादास्पद प्रयास का मुद्दा बन चुका है।', 'source': \"The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\"}, {'target': 'आम तौर पर हाईवे नियोजन जैसा उबाऊ काम भी अचानक गहन बहस तथा जीवंत गठबंधनों का मुद्दा बन गया है।', 'source': 'The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.'}, {'target': 'आपने द्वारा ड्राइव किए गए मील, तथा संभवतः ड्राइव किए गए स्थान का विवरण रखने - और फिर इस सूचना का उपयोग टैक्स बिल तैयार करने के लिए - सरकार को इन ब्लैक बॉक्स का उपयोग करने की अनुमति देने के पक्ष में समर्थन जुटाने के लिए लिबरेटेरियन पर्यावरणीय समूहों के साथ मिल गए हैं।', 'source': 'Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.'}]\n",
      "[{'target': \"महानगर पालिका अंतर्गत दत्तात्रय नगर माध्यमिक स्कूल के विद्यार्थियों ने काल्पनिक किला 'दत्तगढ़' बनाकर अपनी कल्पनाशक्ति का परिचय दिया।\", 'source': 'Students of the Dattatreya city Municipal corporation secondary school demonstrated their imagination power by creating the fictitious fort \"Duttgarh\".'}, {'target': 'प्रधानाध्यापक संध्या मेडपल्लीवार के प्रोत्साहित करने पर शिक्षकों व विद्यार्थियों ने मिट्टïी से किले का निर्माण किया।', 'source': 'With encouragement from Principal Sandhya Medpallivaar the teachers and students built the fort out of clay.'}, {'target': 'मनपा शिक्षक संघ के अध्यक्ष राजेश गवरे ने स्कूल को भेंट देकर सराहना की।', 'source': 'Rajesh Gavre, the President of the MNPA teachers association, honoured the school by presenting the award.'}, {'target': 'किले का परीक्षण रमेश सातपुते ने किया।', 'source': 'Ramesh Saatpute examined the fort.'}, {'target': 'किला निर्माण में निखिल कावले, दर्शन गेड़ेकर, साहिल मेश्राम इन विद्यार्थियों ने सहभाग लिया।', 'source': 'Students like Nikhil Kavle, Darshan Gedekar, Sahil Meshram participated in building the fort.'}]\n"
     ]
    }
   ],
   "source": [
    "train_pairs = []\n",
    "for item in ds['train']['translation']:\n",
    "    train_pairs.append({\n",
    "        'target': item['hi'],\n",
    "        'source': item['en']\n",
    "    })\n",
    "print(train_pairs[:5])\n",
    "\n",
    "test_pairs = []\n",
    "for item in ds['test']['translation']:\n",
    "    test_pairs.append({\n",
    "        'target': item['hi'],\n",
    "        'source': item['en']\n",
    "    })\n",
    "print(test_pairs[:5])\n",
    "\n",
    "validation_pairs = []\n",
    "for item in ds['validation']['translation']:\n",
    "    validation_pairs.append({\n",
    "        'target': item['hi'],\n",
    "        'source': item['en']\n",
    "    })\n",
    "print(validation_pairs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb5f76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "def noise_filter(pairs):\n",
    "  pairs = [p for p in pairs \n",
    "           if len(p[\"source\"].split()) <= 80 \n",
    "           and len(p[\"target\"].split()) <= 80]\n",
    "  return pairs\n",
    "\n",
    "train_pairs = noise_filter(train_pairs)\n",
    "validation_pairs = noise_filter(validation_pairs)\n",
    "test_pairs = noise_filter(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562bacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\"../data/raw/train-en-hi.json\", 'w+')\n",
    "json.dump(train_pairs, f, ensure_ascii=False, indent=4)\n",
    "f.close()\n",
    "f = open(\"../data/raw/validation-en-hi.json\", \"w+\")\n",
    "json.dump(validation_pairs, f, ensure_ascii=False, indent=4)\n",
    "f.close()\n",
    "f = open(\"../data/raw/test-en-hi.json\", \"w+\")\n",
    "json.dump(test_pairs, f, ensure_ascii=False, indent=4)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52fda3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/raw/spm_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for p in train_pairs:\n",
    "        f.write(p[\"source\"] + \"\\n\")\n",
    "        f.write(p[\"target\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429ddf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS IN COLAB\n",
    "# import os\n",
    "# import sentencepiece as spm\n",
    "\n",
    "# os.makedirs(\"../data/tokenizer\", exist_ok=True)\n",
    "\n",
    "# spm.SentencePieceTrainer.Train(\n",
    "#     input=\"../data/raw/spm_corpus.txt\",\n",
    "#     model_prefix=\"../data/tokenizer/en_hi_spm\",\n",
    "#     vocab_size=32000,\n",
    "#     character_coverage=1.0,\n",
    "#     model_type='bpe'\n",
    "# )\n",
    "\n",
    "# print(\"Tokenizer trained & saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3facb5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"../models/translation/en_hi_spm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb99eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/raw/train-en-hi.json\", encoding=\"utf-8\") as f:\n",
    "    train_pairs = json.load(f)\n",
    "\n",
    "tokenized_train = []\n",
    "for p in train_pairs:\n",
    "    src_ids = sp.encode(p[\"source\"], out_type=int)\n",
    "    tgt_ids = sp.encode(p[\"target\"], out_type=int)\n",
    "    tokenized_train.append({\"src_ids\": src_ids, \"tgt_ids\": tgt_ids})\n",
    "\n",
    "with open(\"../data/raw/test-en-hi.json\", encoding=\"utf-8\") as f:\n",
    "    test_pairs = json.load(f)\n",
    "tokenized_test = []\n",
    "for p in test_pairs:\n",
    "    src_ids = sp.encode(p[\"source\"], out_type=int)\n",
    "    tgt_ids = sp.encode(p[\"target\"], out_type=int)\n",
    "    tokenized_test.append({\"src_ids\": src_ids, \"tgt_ids\": tgt_ids})\n",
    "\n",
    "with open(\"../data/raw/validation-en-hi.json\", encoding=\"utf-8\") as f:\n",
    "    validation_pairs = json.load(f)\n",
    "tokenized_validation = []\n",
    "for p in validation_pairs:\n",
    "    src_ids = sp.encode(p[\"source\"], out_type=int)\n",
    "    tgt_ids = sp.encode(p[\"target\"], out_type=int)\n",
    "    tokenized_validation.append({\"src_ids\": src_ids, \"tgt_ids\": tgt_ids})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
